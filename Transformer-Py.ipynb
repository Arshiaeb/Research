{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import pickle\n",
    "from torch.nn.functional import pad, one_hot\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return both the feature and the corresponding label\n",
    "        return self.features[idx], self.labels[idx]\n",
    "    \n",
    "def create_padding_mask(tensor_input):\n",
    "    mask = (tensor_input.sum(dim=2) != 0).float()\n",
    "    return mask\n",
    "    \n",
    "train_data_name = \"Train_Data_100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_data_name, 'rb') as file:\n",
    "    train_data_set = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trun_data = train_data_set[\"System_EWS\"]\n",
    "trun_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([68, 650, 6])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trun_data = train_data_set[\"System_EWS\"]\n",
    "seq_trun = [torch.from_numpy(run[:,:6]).float() for run in trun_data]\n",
    "\n",
    "seq_padded_2 = []\n",
    "max_length = 650\n",
    "for run in seq_trun:\n",
    "    pad_amount = max_length - run.shape[0]\n",
    "    run_padded_2 = pad(run, (0, 0, pad_amount, 0))\n",
    "    seq_padded_2.append(run_padded_2)\n",
    "\n",
    "tensor_input_2 = torch.stack(seq_padded_2)\n",
    "tensor_input_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [torch.tensor(label) for label in train_data_set[\"null\"]]\n",
    "labels_t = torch.stack(labels)\n",
    "labels_oh = one_hot(labels_t).float()\n",
    "\n",
    "seq = [torch.from_numpy(run).float() for run in train_data_set[\"System_EWS\"]]\n",
    "seq_padded = []\n",
    "max_length = 650\n",
    "for run in seq:\n",
    "    pad_amount = max_length - run.shape[0]\n",
    "    run_padded = pad(run, (0, 0, pad_amount, 0))\n",
    "    seq_padded.append(run_padded)\n",
    "\n",
    "tensor_input = torch.stack(seq_padded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Features: torch.Size([17, 650, 6]) torch.float32\n",
      "Batch Labels: torch.Size([17, 2]) torch.float32\n",
      "Batch Features: torch.Size([17, 650, 6]) torch.float32\n",
      "Batch Labels: torch.Size([17, 2]) torch.float32\n",
      "Batch Features: torch.Size([17, 650, 6]) torch.float32\n",
      "Batch Labels: torch.Size([17, 2]) torch.float32\n",
      "Batch Features: torch.Size([17, 650, 6]) torch.float32\n",
      "Batch Labels: torch.Size([17, 2]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Create dataset and dataloader\n",
    "dataset = MyDataset(tensor_input_2, labels_oh)\n",
    "\n",
    "batch_size = 17\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Example: iterate over batches of (features, labels)\n",
    "for batch_data, batch_labels in dataloader:\n",
    "    print(\"Batch Features:\", batch_data.shape, batch_data.dtype)\n",
    "    print(\"Batch Labels:\", batch_labels.shape, batch_labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Transformer model for classification with padding and masking\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, num_heads, num_layers, num_classes, dropout=0.15 ):\n",
    "\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        self.model_dim = d_model\n",
    "        self.batch_norm = nn.BatchNorm1d(d_model)\n",
    "        self.projection = nn.Linear(input_dim, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model=d_model, nhead = num_heads, dropout = dropout, dim_feedforward=d_model,batch_first=True)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers, enable_nested_tensor = True)\n",
    "        self.classification_head = nn.Linear(d_model, num_classes)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            # Xavier Initialization for Linear layers\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "        \n",
    "        elif isinstance(module, nn.TransformerEncoderLayer):\n",
    "            # Kaiming initialization for Transformer encoder layers\n",
    "            nn.init.kaiming_uniform_(module.self_attn.in_proj_weight, nonlinearity='relu')\n",
    "            nn.init.zeros_(module.self_attn.in_proj_bias)\n",
    "            nn.init.kaiming_uniform_(module.linear1.weight, nonlinearity='relu')\n",
    "            nn.init.zeros_(module.linear1.bias)\n",
    "            nn.init.kaiming_uniform_(module.linear2.weight, nonlinearity='relu')\n",
    "            nn.init.zeros_(module.linear2.bias)\n",
    "\n",
    "    def forward(self, src): # can add src_key_padding_mask\n",
    "\n",
    "        src = self.projection(src) #* torch.sqrt(torch.tensor(self.model_dim, dtype=torch.float32))\n",
    "\n",
    "        # Apply batch normalization\n",
    "        # src = src.permute(0, 2, 1)  \n",
    "        # src = self.batch_norm(src)\n",
    "        # src = src.permute(0, 2, 1)\n",
    "\n",
    "        src = self.pos_encoder(src)\n",
    "        #src = src.permute(1,0,2)\n",
    "        transformer_output = self.transformer_encoder(src,is_causal = False, src_key_padding_mask = create_padding_mask(src) ) # can add src_key_padding_mask\n",
    "        # transformer_output = transformer_output.permute(1,0,2)\n",
    "        # Aggregate the output of the transformer (e.g., using mean pooling or just the first token)\n",
    "        pooled_output = transformer_output.mean(dim=1)\n",
    "        \n",
    "        # Pass through classification layer\n",
    "        output = self.classification_head(pooled_output)\n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len=650):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:,:x.size(1)].requires_grad_(False)\n",
    "        \n",
    "        return self.dropout(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask shape: torch.Size([17, 650])\n",
      "data shape:torch.Size([17, 650, 6])\n",
      "label shape:torch.Size([17, 2])\n",
      "mask shape: torch.Size([17, 650])\n",
      "data shape:torch.Size([17, 650, 6])\n",
      "label shape:torch.Size([17, 2])\n",
      "mask shape: torch.Size([17, 650])\n",
      "data shape:torch.Size([17, 650, 6])\n",
      "label shape:torch.Size([17, 2])\n",
      "mask shape: torch.Size([17, 650])\n",
      "data shape:torch.Size([17, 650, 6])\n",
      "label shape:torch.Size([17, 2])\n"
     ]
    }
   ],
   "source": [
    "for batch_data, batch_labels in dataloader:\n",
    "    # Forward pass with masking\n",
    "    src_key_padding_mask = create_padding_mask(batch_data)\n",
    "    print(f\"mask shape: {src_key_padding_mask.shape}\")  # Output will have shape: [batch_size, num_classes]\n",
    "    print(f\"data shape:{batch_data.shape}\")\n",
    "    print(f\"label shape:{batch_labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage with variable-length sequences:\n",
    "dim_feedforward = 64\n",
    "input_dim = 6  # Number of features\n",
    "d_model = 64  # Transformer model dimension\n",
    "num_heads = 4   # Number of attention heads\n",
    "num_layers = 6  # Number of transformer layers\n",
    "num_classes = 2  # Number of classes for classification\n",
    "dropout = 0.15   # Dropout rate\n",
    "\n",
    "model = TransformerClassifier(input_dim, d_model, num_heads, num_layers, num_classes, dropout)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([17, 2]),output: tensor([[ 0.2085,  0.0593],\n",
      "        [ 0.0629, -0.1134],\n",
      "        [ 0.3149,  0.1496],\n",
      "        [ 0.2541,  0.1566],\n",
      "        [ 0.0247, -0.0236],\n",
      "        [ 0.3004,  0.2610],\n",
      "        [ 0.2490,  0.2747],\n",
      "        [ 0.1579,  0.2281],\n",
      "        [ 0.2304,  0.0931],\n",
      "        [ 0.3020,  0.3344],\n",
      "        [ 0.3237,  0.2039],\n",
      "        [ 0.1554, -0.0019],\n",
      "        [ 0.2619,  0.1886],\n",
      "        [ 0.0538, -0.0641],\n",
      "        [ 0.3109,  0.2577],\n",
      "        [-0.1859, -0.2020],\n",
      "        [ 0.0816, -0.1800]], grad_fn=<AddmmBackward0>)\n",
      "labels: tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "Loss: 0.7045390605926514\n",
      "output shape: torch.Size([17, 2]),output: tensor([[-0.2760,  1.9111],\n",
      "        [-0.3116,  2.1287],\n",
      "        [-0.3292,  2.0412],\n",
      "        [-0.2087,  1.9875],\n",
      "        [-0.2806,  2.1113],\n",
      "        [-0.3466,  2.0312],\n",
      "        [-0.3373,  2.0930],\n",
      "        [-0.2637,  2.3687],\n",
      "        [-0.2334,  2.3923],\n",
      "        [-0.2259,  2.1215],\n",
      "        [-0.2621,  2.0731],\n",
      "        [-0.3400,  2.0215],\n",
      "        [-0.3933,  1.8744],\n",
      "        [-0.3283,  2.4113],\n",
      "        [-0.2718,  1.8959],\n",
      "        [-0.3736,  1.8573],\n",
      "        [-0.1445,  2.0920]], grad_fn=<AddmmBackward0>)\n",
      "labels: tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "Loss: 0.7717958092689514\n",
      "output shape: torch.Size([17, 2]),output: tensor([[-0.1653,  2.3448],\n",
      "        [-0.1397,  1.7422],\n",
      "        [-0.1030,  1.6972],\n",
      "        [-0.1388,  2.3871],\n",
      "        [-0.0985,  2.3375],\n",
      "        [-0.1047,  1.7684],\n",
      "        [-0.0773,  1.7748],\n",
      "        [-0.1723,  1.5973],\n",
      "        [-0.0817,  1.7226],\n",
      "        [-0.1127,  2.3260],\n",
      "        [-0.1090,  1.9348],\n",
      "        [-0.0813,  2.2951],\n",
      "        [-0.0238,  1.6373],\n",
      "        [-0.1220,  1.5964],\n",
      "        [-0.0687,  1.8096],\n",
      "        [-0.1256,  1.7561],\n",
      "        [-0.1244,  2.0068]], grad_fn=<AddmmBackward0>)\n",
      "labels: tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n",
      "Loss: 0.5809292793273926\n",
      "output shape: torch.Size([17, 2]),output: tensor([[ 9.0195e-02,  1.4086e+00],\n",
      "        [ 5.2020e-02,  1.4993e+00],\n",
      "        [-7.7695e-04,  1.9141e+00],\n",
      "        [-1.9130e-02,  1.8543e+00],\n",
      "        [ 9.5364e-02,  1.6074e+00],\n",
      "        [ 7.0931e-03,  1.3213e+00],\n",
      "        [-1.4998e-02,  1.4120e+00],\n",
      "        [ 1.0697e-01,  1.4407e+00],\n",
      "        [ 9.5385e-02,  1.4213e+00],\n",
      "        [ 1.8015e-02,  1.4334e+00],\n",
      "        [ 2.5477e-02,  1.3669e+00],\n",
      "        [ 7.4363e-02,  1.4826e+00],\n",
      "        [ 1.1562e-01,  1.4298e+00],\n",
      "        [-3.2455e-02,  1.8674e+00],\n",
      "        [ 3.3141e-02,  1.3046e+00],\n",
      "        [-1.9256e-02,  1.9164e+00],\n",
      "        [ 1.4664e-02,  1.2574e+00]], grad_fn=<AddmmBackward0>)\n",
      "labels: tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "Loss: 0.4581894278526306\n"
     ]
    }
   ],
   "source": [
    "for batch_data, batch_labels in dataloader:\n",
    "    # Forward pass with masking\n",
    "    output = model(batch_data)\n",
    "    print(f\"output shape: {output.shape},output: {output}\")  # Output will have shape: [batch_size, num_classes]\n",
    "    print(f\"labels: {batch_labels}\")\n",
    "    # Example of using CrossEntropyLoss for training\n",
    "    loss = criterion(output, batch_labels)\n",
    "    print(f\"Loss: {loss.item()}\")\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
