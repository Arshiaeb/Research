{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 12)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 128, 256)     3328        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 128, 256)    512         ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 128, 256)    1051904     ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128, 256)     0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 128, 256)    0           ['dropout[0][0]',                \n",
      " da)                                                              'conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 128, 256)    512         ['tf.__operators__.add[0][0]']   \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 128, 256)     65792       ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128, 256)     0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 128, 256)     65792       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 128, 256)    0           ['conv1d_2[0][0]',               \n",
      " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 128, 256)    512         ['tf.__operators__.add_1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 128, 256)    1051904     ['layer_normalization_2[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 128, 256)     0           ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 128, 256)    0           ['dropout_2[0][0]',              \n",
      " mbda)                                                            'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 128, 256)    512         ['tf.__operators__.add_2[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 128, 256)     65792       ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 128, 256)     0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 128, 256)     65792       ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 128, 256)    0           ['conv1d_4[0][0]',               \n",
      " mbda)                                                            'tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 128, 256)    512         ['tf.__operators__.add_3[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 128, 256)    1051904     ['layer_normalization_4[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 128, 256)     0           ['multi_head_attention_2[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 128, 256)    0           ['dropout_4[0][0]',              \n",
      " mbda)                                                            'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 128, 256)    512         ['tf.__operators__.add_4[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 128, 256)     65792       ['layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 128, 256)     0           ['conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 128, 256)     65792       ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 128, 256)    0           ['conv1d_6[0][0]',               \n",
      " mbda)                                                            'tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 128, 256)    512         ['tf.__operators__.add_5[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 128, 256)    1051904     ['layer_normalization_6[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 128, 256)     0           ['multi_head_attention_3[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 128, 256)    0           ['dropout_6[0][0]',              \n",
      " mbda)                                                            'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 128, 256)    512         ['tf.__operators__.add_6[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 128, 256)     65792       ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 128, 256)     0           ['conv1d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 128, 256)     65792       ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 128, 256)    0           ['conv1d_8[0][0]',               \n",
      " mbda)                                                            'tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 256)         0           ['tf.__operators__.add_7[0][0]'] \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          32896       ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 10)           1290        ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,775,562\n",
      "Trainable params: 4,775,562\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the Transformer model for classification with padding and masking\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, model_dim, num_heads, num_layers, num_classes, dropout=0.1):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        self.model_dim = model_dim\n",
    "        \n",
    "        # Embedding layer to convert input to model dimensions\n",
    "        self.embedding = nn.Linear(input_dim, model_dim)\n",
    "        \n",
    "        # Positional encoding for variable length sequences\n",
    "        self.pos_encoder = PositionalEncoding(model_dim, dropout)\n",
    "        \n",
    "        # Transformer encoder\n",
    "        encoder_layers = TransformerEncoderLayer(model_dim, num_heads, model_dim, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers)\n",
    "        \n",
    "        # Classification head\n",
    "        self.fc_out = nn.Linear(model_dim, num_classes)  # Output layer for classification\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        src = self.embedding(src) * torch.sqrt(torch.tensor(self.model_dim, dtype=torch.float32))\n",
    "        src = self.pos_encoder(src)\n",
    "        transformer_output = self.transformer_encoder(src, src_mask)\n",
    "        \n",
    "        # Aggregate the output of the transformer (e.g., using mean pooling or just the first token)\n",
    "        pooled_output = transformer_output.mean(dim=0)\n",
    "        \n",
    "        # Pass through classification layer\n",
    "        output = self.fc_out(pooled_output)\n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, model_dim, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, model_dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, model_dim, 2).float() * (-torch.log(torch.tensor(10000.0)) / model_dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# Example usage with variable-length sequences:\n",
    "input_dim = 10  # Number of features\n",
    "model_dim = 32  # Transformer model dimension\n",
    "num_heads = 4   # Number of attention heads\n",
    "num_layers = 3  # Number of transformer layers\n",
    "num_classes = 5  # Number of classes for classification\n",
    "dropout = 0.1   # Dropout rate\n",
    "\n",
    "# Example of a batch of sequences with different lengths\n",
    "seq1 = torch.randn(8, 10)  # 8 time steps, 10 features\n",
    "seq2 = torch.randn(5, 10)  # 5 time steps, 10 features\n",
    "seq3 = torch.randn(7, 10)  # 7 time steps, 10 features\n",
    "\n",
    "# Pad the sequences to match the longest sequence length\n",
    "padded_sequences = pad_sequence([seq1, seq2, seq3], batch_first=False)  # Shape: [max_seq_len, batch_size, input_dim]\n",
    "\n",
    "# Create a mask to ignore the padded positions\n",
    "def create_mask(padded_seqs):\n",
    "    # Create a binary mask where 1 indicates valid tokens and 0 indicates padding\n",
    "    return (padded_seqs != 0).float()\n",
    "\n",
    "src_mask = create_mask(padded_sequences[:, :, 0])  # Shape: [max_seq_len, batch_size]\n",
    "\n",
    "# Initialize the transformer classification model\n",
    "model = TransformerClassifier(input_dim, model_dim, num_heads, num_layers, num_classes, dropout)\n",
    "\n",
    "# Forward pass with masking\n",
    "output = model(padded_sequences, src_mask)\n",
    "print(output.shape)  # Output will have shape: [batch_size, num_classes]\n",
    "\n",
    "# Example of using CrossEntropyLoss for training\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "labels = torch.randint(0, num_classes, (padded_sequences.size(1),))  # Random labels for testing\n",
    "loss = criterion(output, labels)\n",
    "print(f\"Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
